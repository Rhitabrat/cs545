{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# HW #2: Neural Networks\n",
    "\n",
    "[change this (hw #1)]\n",
    "This experiment uses a neural network of ten Networks encapsulated in a Network class object.\n",
    "The Networks themselves exist in a weight matrix property of the Network class that is returned\n",
    "as a Numpy array from the train() method.  There are two layers in this network.\n",
    "An input layer represented as xᴷ of 784 inputs, plus one for the bias.  And an output layer\n",
    "represented as yᴷ. There are no hidden layers in this experiment.  We ran the experiment with learning\n",
    "rates, represented as η, of 0.00001, 0.001, and 0.1.\n",
    "\n",
    "     xᴷ      The input layer vector of 784 (+1 bias) pixels of a single image\n",
    "     yᴷ      The output (activation) layer vector of 10 nodes representing activation level of a digit\n",
    "     tᴷ      The output layer vector of 10 nodes from the labeled training data\n",
    "     wᵢ      The weight element at index i of 785 weights\n",
    "     Δwᵢ     The gradient or vector derivative in order to minimize the cost function\n",
    "\n",
    "The Network Learning Algorithm was implemented by forwarding an activation vector of 10 elements\n",
    "to the output layer in the forward() method.\n",
    "\n",
    "\n",
    "      yᴷ = a(w · x)\n",
    "\n",
    "After forwarding the activation layer, we updated weights through back propagation using\n",
    "the following formula in the back() method:\n",
    "\n",
    "     Δwᵢ = η(tᴷ - yᴷ)xᵢᴷ\n",
    "      wᵢ ⟵ wᵢ + Δwᵢ\n",
    "\n",
    "\n",
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import network as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First we instantiate our Network object (or rather network of 10 Networks).\n",
    "We set the bias, the number of epochs and the sizes of our input and output layers.\n",
    "\n",
    "The Network constructor optionally takes in the training and test file names and loads them\n",
    "into Numpy arrays.\n",
    "\n",
    "Here are the parameters that actually will remain static for all of our experiments.\n",
    "In fact, aside from the filenames for the training and validation samples, they are the\n",
    "the default parameter values for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_file = 'mnist_train.csv'\n",
    "test_file = 'mnist_validation.csv'\n",
    "\n",
    "bias = 1\n",
    "epochs = 50\n",
    "rate = 0.1\n",
    "target = 0.9\n",
    "initial_weight = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here are the the parameters that will actually change during the experiments:\n",
    "\n",
    "#### Hidden Input Size\n",
    "This is number of nodes in the hidden layer.  Conceptually, this represents the number of\n",
    "intermediate things (or abstractions) that this network will learn about hand written digits.\n",
    "Naively, we might be tempted to think of this as different shapes we find in a handwritten image.\n",
    "For example, both a 9 and an 8 have a circle at the upper have of the image. Both a 5 and a 3,\n",
    "have a semicircle in the lower half of an image.  There are many shapes that the digits below share.\n",
    "\n",
    "123456789\n",
    "\n",
    "However,\n",
    "The one parameter that will change in this entire projec is the momentum, represented by α in the lecture slides."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_size = 785\n",
    "hidden_size = 20\n",
    "output_size = 10\n",
    "sizes = [input_size, hidden_size, output_size]\n",
    "\n",
    "momentum = 0.9"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train with a hidden layer size of 20 nodes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 785\n",
    "hidden_size = 20\n",
    "output_size = 10\n",
    "\n",
    "sizes = [input_size, hidden_size, output_size]\n",
    "\n",
    "n = nn.Network(sizes=sizes, train_filename=train_file, test_filename=test_file, bias=bias)\n",
    "wᵢ, wⱼ, accuracy = n.train(η=rate, epochs=epochs)\n",
    "assert(wᵢ.shape == (785, 20))\n",
    "assert(wⱼ.shape == (20 + bias, 10))\n",
    "assert(accuracy > .90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with a hidden layer size of 50 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "sizes = [input_size, hidden_size, output_size]\n",
    "n.resize(sizes)\n",
    "wᵢ, wⱼ, accuracy = n.train(epochs=epochs)\n",
    "assert(accuracy > .90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with a hidden layer size of 100 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hidden_size = 100\n",
    "sizes = [input_size, hidden_size, output_size]\n",
    "n.resize(sizes)\n",
    "wᵢ, wⱼ, accuracy = n.train(epochs=epochs)\n",
    "assert(accuracy > .90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The digits having the most issues being classified were 8, 5, and 2, all being mistaken for a 3.\n",
    "The rest of the digits did quite well, especially 0, 1, 5, and 7.  That plots and confusions\n",
    "matrices do not show any significant differrences between our three learning rates.\n",
    "\n",
    "I noticed with all them that starting with the Epoch 0 the accuracy was very low (as expected).\n",
    "It was less than 10%.  At Epoch 1, the accuracy jumps to ~85% and then over the next 49 epochs\n",
    "we only get an improvement of 3%.  I am confused by this.  Also, I don't see any oscillations\n",
    "here, so it appears that I am overfitting.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}